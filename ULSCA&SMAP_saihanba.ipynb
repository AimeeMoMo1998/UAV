{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as mathlib\n",
    "import scipy.optimize\n",
    "import math\n",
    "\n",
    " # choose from [1,3,4,6]\n",
    "landcover_index=6\n",
    "\n",
    "if landcover_index==1:\n",
    "    landcover_beginfile=[12]# shrublands\n",
    "    initial_guess_raw_smap=[0.05,0.11,0.11,1.5]\n",
    "    initial_guess_raw_ulsca=[0.05,0.14,0.08,1]\n",
    "    print(\"shrublands\")\n",
    "elif landcover_index==2:\n",
    "    print(\"tree\")\n",
    "elif landcover_index==3:\n",
    "    landcover_beginfile=[4,7,8,13,14]# grass\n",
    "    initial_guess_raw_smap=[0.05,0.13,0.156,1.5]\n",
    "    initial_guess_raw_ulsca=[0.04,0.12,0.18,1.5]\n",
    "    print(\"grass\")\n",
    "elif landcover_index==4:\n",
    "    landcover_beginfile=[2,3,5,6,11,16,19,22,23,24,25,26,27,28,30,32,34,36,38,39,40,43,44]# crop\n",
    "    initial_guess_raw_smap=[0.05,0.11,0.094,3.5]\n",
    "    initial_guess_raw_ulsca=[0.07,0.1,0.08,0.5]\n",
    "    print(\"crop\")\n",
    "elif landcover_index==5:\n",
    "    print(\"cropandnatural\")\n",
    "elif landcover_index==6:\n",
    "    landcover_beginfile=[9,10]# bareland\n",
    "    initial_guess_raw_smap=[0,0,0.15,0]\n",
    "    initial_guess_raw_ulsca=[0,0,0.05,0]\n",
    "    print(\"bareland\")\n",
    "\n",
    "# choose one ï¼šsmap or ulsca\n",
    "omega=initial_guess_raw_ulsca[0]\n",
    "b=initial_guess_rawulsca[1]\n",
    "h=initial_guess_rawulsca[2]\n",
    "StemFactor=initial_guess_rawulsca[3]\n",
    "tb_bias=30\n",
    "\n",
    "plandcover_beginfile = [i-1 for i in landcover_beginfile]\n",
    "for myindex in plandcover_beginfile:\n",
    "    nameall = np.genfromtxt(\"./matchfile_NEW.csv\",delimiter=\",\",skip_header=1,dtype=str,usecols=range(2),invalid_raise=False,filling_values=np.nan)\n",
    "    name=nameall[myindex,0].astype(str)   # get drone latitude\n",
    "    fpath = \"./draw UAV/\"+name+\"/\"\n",
    "    radfile =  name+\".dat\"\n",
    "    flogfile = nameall[myindex,1].astype(str)   # get drone longitude\n",
    "    # flogfile = name+\"_p31gps.csv\"\n",
    "    print(name)\n",
    "    #### v2.csv is Litchi's flightlog ####\n",
    "    if flogfile.endswith('v2.csv') or flogfile.endswith('V2.CSV'):\n",
    "        logtype=\"Litchi\"\n",
    "        UTCerror = 0\n",
    "        #call function to load and convert Litchi format flightlog\n",
    "        #print(\"Detected .csv format flightlog, proceeding with Litchi format.\")\n",
    "\n",
    "        flog = np.genfromtxt(fpath+flogfile,delimiter=\",\",skip_header=1,dtype=str,usecols=range(67),invalid_raise=False,filling_values=np.nan)\n",
    "        datestrings = flog[:,11] # OR COLUMN 12 is Local\n",
    "        tms = flog[:,10].astype(float)  # drone flight ticker time in milliseconds\n",
    "        lat = flog[:,0].astype(float)   # get drone latitude\n",
    "        lon = flog[:,1].astype(float)   # get drone longitude\n",
    "        alt = flog[:,2].astype(float)   #altitude above ground (m)\n",
    "        speed = flog[:,4].astype(float)\n",
    "    #     flystate = flog[:,66].astype(float)\n",
    "        pitch = flog[:,22].astype(float)\n",
    "        roll = flog[:,23].astype(float)\n",
    "        yaw = flog[:,24].astype(float)\n",
    "        dronet = pd.to_datetime(datestrings)+datetime.timedelta(hours=0)\n",
    "\n",
    "        #print(dronet[-1])\n",
    "        dronet=dronet+datetime.timedelta(seconds=0)+datetime.timedelta(hours=0)\n",
    "        dronetnum = (dronet - datetime.datetime(1970, 1, 1)) / datetime.timedelta(seconds=1.)\n",
    "        lonraw = lon\n",
    "        latraw = lat\n",
    "        #print(\"\")\n",
    "        #print(\"Drone Start Time:\")\n",
    "        #print(dronet[0])\n",
    "        #print(\"\")\n",
    "        #print(\"Drone End Time:\")\n",
    "        #print(dronet[-1])\n",
    "        #print(\"\")\n",
    "        #print(\"Done.\")\n",
    "\n",
    "    #### p31gps.csv is the ending for vehcile-based systems. ####\n",
    "    if flogfile.endswith('p31gps.csv') or flogfile.endswith('P31GPS.CSV') or flogfile.endswith('P31GPS.csv'):\n",
    "        logtype=\"P31GPS\"\n",
    "        UTCerror = 0\n",
    "        #call function to load and convert Litchi format flightlog\n",
    "        print(\"Detected Ground-based GPS Telemetry file.\")\n",
    "\n",
    "        flog = np.genfromtxt(fpath+flogfile,delimiter=\",\",skip_header=1,dtype=str,invalid_raise=False,filling_values=np.nan)\n",
    "        day = flog[:,0].astype(int)    # drone flight ticker time in milliseconds\n",
    "        month = flog[:,1].astype(int)  # get drone latitude\n",
    "        year = flog[:,2].astype(int)   # get drone longitude\n",
    "        hour = flog[:,3].astype(int)   #altitude above ground (m)\n",
    "        minute = flog[:,4].astype(int)\n",
    "        second = flog[:,5].astype(int)\n",
    "        lat = flog[:,6].astype(float)\n",
    "        lon = flog[:,7].astype(float)\n",
    "        altabs = flog[:,8].astype(float)\n",
    "        speed = flog[:,9].astype(float)\n",
    "\n",
    "        course = flog[:,10].astype(float)\n",
    "        HDOP = flog[:,11].astype(float)\n",
    "        numsat = flog[:,12].astype(int)\n",
    "\n",
    "        alt = altabs-np.mean(altabs[0:10])\n",
    "\n",
    "        pitch = np.zeros_like(lat)\n",
    "        roll = np.zeros_like(lat)\n",
    "        yaw = np.zeros_like(lat)\n",
    "\n",
    "        #dronet=dronet+datetime.timedelta(seconds=0.0)+datetime.timedelta(hours=0)\n",
    "        #dronetnumdelta = datetime.datetime(year,month,day,hour,minute,second)-datetime.datetime(1970, 1, 1,0,0,0)\n",
    "        datearr      = np.column_stack((year,month,day,hour,minute,second))\n",
    "        dt_ref    = datetime.datetime(1970, 1, 1,0,0,0)\n",
    "        dronetnum  = np.array([(datetime.datetime(y,m,d,h,mi,s)-dt_ref).total_seconds() for y,m,d,h,mi,s in datearr])\n",
    "\n",
    "        dronet  = [datetime.datetime.utcfromtimestamp(ts) for ts in dronetnum]\n",
    "        #dronetnum = dronetnumdelta.total_seconds()\n",
    "        lonraw = lon\n",
    "        latraw = lat\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"GPS file Start Time:\")\n",
    "        print(dronet[0])\n",
    "        print(\"\")\n",
    "        print(\"GPS file End Time:\")\n",
    "        print(\"\")\n",
    "        print(dronet[-1])\n",
    "\n",
    "        print(\"Done.\")\n",
    "\n",
    "\n",
    "    #print(\"Processing Flightlog Data...\",end='',flush=True) \n",
    "    #print(\"Done.\")\n",
    "\n",
    "    #print(\"maxlat:\",np.nanmax(lat))\n",
    "    #print(\"minlat:\",np.nanmin(lat))\n",
    "\n",
    "    #print(\"maxlon:\",np.nanmax(lon))\n",
    "    #print(\"minlon:\",np.nanmin(lon))\n",
    "\n",
    "    if logtype==\"P31GPS\":\n",
    "        alt = 1.5*np.ones_like(alt) # m above ground for fixed (vehicle-based) sensor\n",
    "    #print(\"Loading PoLRa Data...\",end='',flush=True)\n",
    "    DATA = np.genfromtxt(fpath+radfile,delimiter=None,autostrip=True)\n",
    "    #print(\"Done.\")\n",
    "    if 'polra2bool' in locals():  # POLRA2 had different channels\n",
    "        if polra2bool == 'True':\n",
    "            ml = DATA[:,5]     #matched load\n",
    "            cl = DATA[:,6]     #cold load\n",
    "            rv = DATA[:,7]     #v pol\n",
    "            rh = DATA[:,8]     #h pol\n",
    "            Tdet = DATA[:,9]   #detector physical temp\n",
    "            Tml = DATA[:,10]    #matched load physical temp\n",
    "            Tcl = DATA[:,11]    #cold load physical temp\n",
    "            Tpam1 = DATA[:,12]  #external/antenna temp 1\n",
    "            Tpam2 = DATA[:,13]  #external / antenna temp 2\n",
    "            Tpam = (Tpam1+Tpam2)/2\n",
    "            uml = DATA[:,14]   #matched load\n",
    "            ucl = DATA[:,15]   #cold load\n",
    "            urv = DATA[:,16]   #v pol\n",
    "            urh = DATA[:,17]   #h pol\n",
    "\n",
    "    else:  # standard column format since PoLRa3\n",
    "        ###radiometer voltages\n",
    "        cl = DATA[:,5]     #cold load\n",
    "        ml = DATA[:,6]     #matched load\n",
    "        rv = DATA[:,7]     #v pol\n",
    "        rh = DATA[:,8]     #h pol\n",
    "\n",
    "        ###extract physical temperatures and save mean to vector\n",
    "        Tdet = DATA[:,9]   #detector physical temp (null for PoLRa3)\n",
    "        Tml = DATA[:,10]    #matched load physical temp\n",
    "        Tcl = DATA[:,11]    #cold load physical temp\n",
    "        Tpam1 = DATA[:,12]  #aux board temp / ext. 1\n",
    "        Tpam2 = DATA[:,13]  #external temp\n",
    "        Tpam = (Tpam1+Tpam2)/2\n",
    "\n",
    "        ucl = DATA[:,14]   #cold load\n",
    "        uml = DATA[:,15]   #matched load\n",
    "        urv = DATA[:,16]   #v pol\n",
    "        urh = DATA[:,17]   #h pol\n",
    "    # apply a time offset if defined in config file\n",
    "    if 'toffset' not in locals():\n",
    "        #print(\"no time offset\")\n",
    "        toffset = 0\n",
    "\n",
    "    unixtime = DATA[:,4].astype(float)-UTCerror*3600+toffset\n",
    "    radtnum = np.array(unixtime)\n",
    "    drntnum = np.array(dronetnum)\n",
    "    latrad = np.interp(radtnum,drntnum,lat,left=np.nan,right=np.nan)\n",
    "    lonrad = np.interp(radtnum,drntnum,lon,left=np.nan,right=np.nan)\n",
    "    altrad = np.interp(radtnum,drntnum,alt,left=np.nan,right=np.nan)# flight height\n",
    "    #altabsrad = np.interp(radtnum,drntnum,altabs,left=np.nan,right=np.nan)\n",
    "\n",
    "    def getTCL(hclfile,vclfile):\n",
    "        hpars = np.genfromtxt(hclfile)\n",
    "        vpars = np.genfromtxt(vclfile)\n",
    "        return hpars,vpars\n",
    "    hfile = './TclH.txt'         # files containing fit parameters for cold load TB\n",
    "    vfile = './TclV.txt'\n",
    "    hpars,vpars = getTCL(hfile,vfile)\n",
    "\n",
    "    #print(\"Retrieving PoLRa Data...\",end='',flush=True)\n",
    "    Tcl_H = hpars[0]*Tcl+hpars[1] #0.335*Tcl-90\n",
    "    Tcl_V = vpars[0]*Tcl+vpars[1] #0.335*Tcl-90\n",
    "\n",
    "    slopeh=(Tml-Tcl_H)/(ml-cl)\n",
    "    offh = slopeh*(-ml)+Tml\n",
    "    Tb_h = offh+rh*slopeh                   #calibrated h pol\n",
    "\n",
    "    slopev=(Tml-Tcl_V)/(ml-cl)\n",
    "    offv = slopev*(-ml)+Tml\n",
    "    Tb_v = offv+rv*slopev\n",
    "\n",
    "    if landcover_index==3:\n",
    "        #cali tb\n",
    "        Tb_h = Tb_h + tb_bias\n",
    "        Tb_v = Tb_v + tb_bias\n",
    "        #cali tb\n",
    "\n",
    "\n",
    "    cleanTB_h=Tb_h\n",
    "    cleanTB_v=Tb_v\n",
    "    stdthresh=1\n",
    "    cleanTB_h[urv>stdthresh]=np.nan  #apply standard deviation filter\n",
    "    cleanTB_h[urh>stdthresh]=np.nan  #both polarizations filtered together\n",
    "    cleanTB_v[urv>stdthresh]=np.nan  #apply standard deviation filter\n",
    "    cleanTB_v[urh>stdthresh]=np.nan  #both polarizations filtered together\n",
    "    cleanTB_v[np.isnan(cleanTB_h)]=np.nan   #make sure we have both Tbs or both NaN\n",
    "    cleanTB_h[np.isnan(cleanTB_v)]=np.nan   #make sure we have both Tbs or both NaN\n",
    "\n",
    "    # lat[np.isnan(cleanTB_v)]=np.nan\n",
    "    # lon[np.isnan(cleanTB_v)]=np.nan\n",
    "    # print(cleanTB_h,cleanTB_v)\n",
    "#     plt.figure()\n",
    "#     plt.plot(cleanTB_h)\n",
    "#     plt.plot(cleanTB_v)\n",
    "#     plt.legend(['TB_h','TB_v'])\n",
    "\n",
    "    tsec = unixtime-unixtime[0]\n",
    "    tmin = tsec/60\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(tmin,ml)\n",
    "#     plt.plot(tmin,cl)\n",
    "#     # plt.plot(tmin,rv)\n",
    "#     # plt.plot(tmin,rh)\n",
    "#     plt.ylabel('Detector Voltage (mV)')\n",
    "#     plt.legend(['Matched Load','Cold Load'])\n",
    "#     # plt.legend(['Matched Load','Cold Load','Antenna V','Antenna H'])\n",
    "#     plt.title('Raw Voltages')\n",
    "#     plt.grid()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(tmin,Tml,'-o')\n",
    "#     plt.plot(tmin,Tcl,'-o')\n",
    "#     plt.plot(tmin,Tpam,'-o')\n",
    "#     plt.ylabel('Physical Temperatures (K)')\n",
    "#     plt.legend(['Matched Load','Cold Load','Antenna','Detector'])\n",
    "#     plt.grid()\n",
    "    #print(\"Done.\")\n",
    "\n",
    "\n",
    "    NDVIref=0.851 # annual max NDVI\n",
    "    NDVI=0.4 \n",
    "    T_g=23+273.15 # surface temperature\n",
    "\n",
    "    ps=1.51 # bulk density\n",
    "    sand=4 # 100%\n",
    "    clay=20 # 100%\n",
    "    # flogfile\n",
    "\n",
    "    supp_fpath = \"./supplement_data.csv\" #old temperature 'TB_soil_oldt.csv'\n",
    "    supp = pd.read_csv(supp_fpath)\n",
    "    # print(supp)\n",
    "    supp_name=supp[\"filename\"].astype(str) \n",
    "    supp_namew=supp[\"wfilename\"].astype(str) \n",
    "    NDVIref_all = supp[\"NDVI_ref\"].astype(float) \n",
    "    NDVI_all = supp[\"NDVI\"].astype(float) \n",
    "    T_s_all = supp[\"Soil_temperature_level1\"].astype(float)\n",
    "    T_v_all = supp[\"skin_temperature(vegetation_t)\"].astype(float)\n",
    "    T_w_all = supp[\"ground_temperature\"].astype(float)\n",
    "    ps_all = supp[\"bulk_densi\"].astype(float)\n",
    "    sand_all = supp[\"sand100%\"].astype(float) \n",
    "    clay_all = supp[\"clay100%\"].astype(float)   \n",
    "    mode_all=supp[\"landuse\"].astype(str)\n",
    "    w_Tb_all = supp[\"w_Tb\"].astype(float)\n",
    "    timeflag_all= supp[\"timeflag\"].astype(str)\n",
    "    slope_all = supp[\"slope20\"].astype(float)  \n",
    "    index=np.where(supp_name==flogfile)\n",
    "    #print(index[0].astype(int))\n",
    "\n",
    "    if np.array(timeflag_all[index[0]])[0]==\"winter\":\n",
    "        mode=\"bareland\"\n",
    "    else:\n",
    "        mode=np.array(mode_all[index[0]])[0]\n",
    "\n",
    "    # if mode==\"crop\" or mode==\"grass\" or mode==\"cropandnatural\":\n",
    "    #     NDVIref=np.array(NDVI_all[index[0]])[0]\n",
    "    # else:\n",
    "    #     NDVIref = np.array(NDVIref_all[index[0]])[0]\n",
    "\n",
    "\n",
    "    # NDVIref = np.array(NDVIref_all[index[0]])[0]\n",
    "    NDVI = np.array(NDVI_all[index[0]])[0]\n",
    "    T_s = np.array(T_s_all[index[0]])[0]\n",
    "    T_v = np.array(T_v_all[index[0]])[0]\n",
    "    T_w = np.array(T_w_all[index[0]])[0]\n",
    "    w_Tb = np.array(w_Tb_all[index[0]])[0]\n",
    "    ps = np.array(ps_all[index[0]])[0]\n",
    "    sand = np.array(sand_all[index[0]])[0]\n",
    "    clay = np.array(clay_all[index[0]])[0]\n",
    "    slope = np.array(slope_all[index[0]])[0]\n",
    "\n",
    "    slopefile = pd.read_csv(fpath+\"Export_Output.txt\", sep=',') \n",
    "    \n",
    "    viewangle=40.0\n",
    "    radtnum = np.array(unixtime)\n",
    "    drntnum = np.array(dronetnum)\n",
    "    rollradt = np.interp(radtnum,drntnum,roll,left=np.nan,right=np.nan)\n",
    "   \n",
    "    #careful with mount orientation\n",
    "    alpha = viewangle-rollradt-theta_bias          #incidence angle after roll correction\n",
    "    # nominal mount direction\n",
    "    #print(\"mean look angle:\",np.nanmean(alpha))\n",
    "\n",
    "    ##### Apply cable loss correction\n",
    "    loss_ratio = 0.5 #may depend on system! (whitey had therm outside Alu)\n",
    "    Teff = loss_ratio*Tpam+(1-loss_ratio)*Tml #effective temperature of transmission line loss\n",
    "    #print(\"Applying Cable Loss Correction...\",end='',flush=True)\n",
    "    Loss_V = vpars[2]\n",
    "    Loss_H = hpars[2]\n",
    "    t_cablev = 10**(Loss_V/10)\n",
    "    t_cableh = 10**(Loss_H/10)\n",
    "    cleanTB_h = (cleanTB_h-(1-t_cableh)*Teff)/(t_cableh)\n",
    "    cleanTB_v = (cleanTB_v-(1-t_cablev)*Teff)/(t_cablev)\n",
    "    raw_cleanTB_h = cleanTB_h\n",
    "    raw_cleanTB_v = cleanTB_v\n",
    "    #print(\"done\")\n",
    "\n",
    "    ## ew\n",
    "    ew1=80-0.4*(T_w-293.15) \n",
    "\n",
    "    def PureWater(T, freq):\n",
    "\n",
    "        \"\"\"\n",
    "        The dielectric constant and the complex refractive index of pure water.\n",
    "        Background information: Meissner, Thomas, and Frank J. Wentz.\"The complex dielectric constant of pure and sea water from microwave satellite observations.\"\n",
    "        IEEE Transactions on Geoscience and remote Sensing 42.9 (2004): 1836-1849.\n",
    "        Epsilon_water, Kw2 = PureWater(T, freq)\n",
    "        T:          temperature [Centigrade]\n",
    "        freq:       frequency [GHz]\n",
    "        \"\"\"\n",
    "        Epsilon_s = (3.70886 * pow(10, 4) - 8.2168 * pow(10, 1) * T) \\\n",
    "                    / (4.21854 * pow(10, 2) + T)\n",
    "        Epsilon_1 = 5.7230 + (2.2379 * pow(10, -2) * T) + (-7.1237 * pow(10, -4) * T ** 2)\n",
    "        Epsilon_inf = 3.6143 + (2.8841 * pow(10, -2) * T)\n",
    "        Nu_1 = (45 + T) / (5.0478 + (-7.0315 * pow(10, -2) * T) + (6.0059 * pow(10, -4) * T ** 2))\n",
    "        Nu_2 = (45 + T) / (1.3652 * pow(10, -1) + (1.4825 * pow(10, -3) * T) + (2.4166 * pow(10, -4) * T ** 2))\n",
    "\n",
    "        Epsilon_water = (Epsilon_s - Epsilon_1) / (1 + 1j * freq / Nu_1) + \\\n",
    "                        (Epsilon_1 - Epsilon_inf) / (1 + 1j * freq / Nu_2) + Epsilon_inf\n",
    "\n",
    "        Kw2 = np.abs((Epsilon_water - 1) / (Epsilon_water + 2)) ** 2\n",
    "        return Epsilon_water, Kw2\n",
    "\n",
    "    ew2=PureWater(T_w-273.15, 1.47)\n",
    "    ew3=ew2[0]\n",
    "    ew=ew3.real\n",
    "    #print(ew3.real)\n",
    "    # Dobson \n",
    "    import numpy as np\n",
    "    sm=np.arange(0,1.01,0.01)\n",
    "\n",
    "\n",
    "    def reverse_DielDobson (wc, ew, sand, clay):\n",
    "        # REAL : wc, sand, clay\n",
    "        # COMPLEX : ew, eps\n",
    "        # REAL : rho_s, rho_b, eps_s, beta, eaa,  epsr, epsi\n",
    "        # REAL, PARAMETER : alphas = 0.65\n",
    "\n",
    "        alphas = 0.65\n",
    "        rho_s = 2.66\n",
    "        rho_b = (sand*1.6 +  clay*1.1 + (100.-sand-clay)*1.2)/100.\n",
    "        eps_s = (1.01 + 0.44 * rho_s)**2. - 0.062  # compare to ATBD: 4.7\n",
    "        wc =np.max(wc)*1.000 # to avoid dividing by zero\n",
    "\n",
    "        beta = (127.48 - 0.519 * sand - 0.152 * clay) / 100.\n",
    "        eaa = 1.0 + (rho_b / rho_s) * (eps_s ** alphas - 1.0)+ (wc ** beta) * (float(ew) ** alphas) - wc\n",
    "        epsr = eaa ** (1./alphas) #å®žéƒ¨\n",
    "        return epsr\n",
    "\n",
    "\n",
    "\n",
    "    epsr = [[0] * len(sm) for _ in range(len(cleanTB_h))]\n",
    "    for i in range(len(cleanTB_h)):\n",
    "        for j in range(len(sm)):\n",
    "            if np.isnan(cleanTB_h[i]) | np.isnan(alpha[i]):\n",
    "                epsr[i][j] = np.nan\n",
    "            else:\n",
    "                epsr[i][j]=reverse_DielDobson(sm[j], ew, sand, clay)\n",
    "    #             print(\"i:\",i,\"j:\",j)\n",
    "    #print(\"done\")\n",
    "   \n",
    "    epsr = np.array(epsr)\n",
    "\n",
    "    ## Define trig functions in degrees\n",
    "    def cosd(deg):\n",
    "        rad=np.cos(deg*np.pi/180)\n",
    "        rad=np.array(rad)\n",
    "        return rad\n",
    "    def sind(deg):\n",
    "        rad=np.sin(deg*np.pi/180)\n",
    "        rad=np.array(rad)\n",
    "        return rad\n",
    "    def tand(deg):\n",
    "        rad=np.tan(deg*np.pi/180)\n",
    "        rad=np.array(rad)\n",
    "        return rad\n",
    "    # tau-omega\n",
    "    VWC = (1.9134*(NDVI**2) - 0.3215*NDVI) + StemFactor*(NDVIref - 0.1) / (1 - 0.1)\n",
    "    tau= b*VWC\n",
    "\n",
    "\n",
    "    e_surf_v=[]\n",
    "    e_soil_v=[]\n",
    "    e_surf_h=[]\n",
    "    e_soil_h=[]\n",
    "    cleanTB_h_retrl=[]\n",
    "    cleanTB_v_retrl=[]\n",
    "\n",
    "    for i in range(101):\n",
    "        ## fresnel\n",
    "        e_soil_h.append((1-(abs((cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                                (cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2))\n",
    "        e_soil_v.append((1-(abs((epsr[:,i]*cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                             (epsr[:,i]*cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2))\n",
    "        ## roughness\n",
    "        e_surf_h.append((1-(abs((cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                                (cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha))))\n",
    "        e_surf_v.append((1-(abs((epsr[:,i]*cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                             (epsr[:,i]*cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha))))\n",
    "\n",
    "\n",
    "        ## tau-omega\n",
    "        cleanTB_h_retrl.append((1-(abs((epsr[:,i]*cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                             (epsr[:,i]*cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha)))*T_s*np.exp(-tau/cosd(alpha))+\n",
    "                               (1-omega)*T_v*(1-np.exp(-tau/cosd(alpha)))*\n",
    "                               (1+(1-(1-(abs((epsr[:,i]*cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                             (epsr[:,i]*cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha))))*np.exp(-tau/cosd(alpha))))    \n",
    "        cleanTB_v_retrl.append((1-(abs((cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                                (cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha)))*T_s*np.exp(-tau/cosd(alpha))+\n",
    "                               (1-omega)*T_v*(1-np.exp(-tau/cosd(alpha)))*\n",
    "                               (1+(1-(1-(abs((cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                                (cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha))))*np.exp(-tau/cosd(alpha))))\n",
    "\n",
    "    #print('done')\n",
    "    df_h=pd.DataFrame()\n",
    "    df_v=pd.DataFrame()\n",
    "    for i in range(101):   \n",
    "        ## tau-omega\n",
    "        frames_h = pd.DataFrame(pd.Series(((1-(abs((epsr[:,i]*cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                             (epsr[:,i]*cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha)))*T_s*np.exp(-tau/cosd(alpha))+\n",
    "                               (1-omega)*T_v*(1-np.exp(-tau/cosd(alpha)))*\n",
    "                               (1+(1-(1-(abs((epsr[:,i]*cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                             (epsr[:,i]*cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha))))*np.exp(-tau/cosd(alpha))))),columns=[str(i)])\n",
    "        df_h=pd.concat([df_h,frames_h], axis=1)\n",
    "        frames_v = pd.DataFrame(pd.Series(((1-(abs((cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                                (cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha)))*T_s*np.exp(-tau/cosd(alpha))+\n",
    "                               (1-omega)*T_v*(1-np.exp(-tau/cosd(alpha)))*\n",
    "                               (1+(1-(1-(abs((cosd(alpha)-np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))/\n",
    "                                (cosd(alpha)+np.sqrt(epsr[:,i]-sind(alpha)*sind(alpha)))))**2)/(np.exp(-h*cosd(alpha)*cosd(alpha))))*np.exp(-tau/cosd(alpha))))),columns=[str(i)])\n",
    "        df_v=pd.concat([df_v,frames_v], axis=1)       \n",
    "    #print(\"done\")\n",
    "\n",
    "    position_a=[]\n",
    "    for i in range(len(cleanTB_h)):  \n",
    "        if np.isnan(cleanTB_h[i]):\n",
    "            position_a.append(np.nan)\n",
    "        else:\n",
    "            min_value = np.nanmin(abs(cleanTB_h[i]-df_h.iloc[i]))\n",
    "            if np.isnan(min_value):\n",
    "                position_a.append(np.nan)\n",
    "            else:\n",
    "                min_index = np.where(abs(cleanTB_h[i]-df_h.iloc[i]) == min_value)\n",
    "    #             print(min_index[0])\n",
    "                aaa=min_index[0]*0.01\n",
    "                position_a.append(aaa[0])\n",
    "\n",
    "    ##change GPS\n",
    "    def millerToXY (lon,lat):\n",
    "        xy_coordinate =[]      \n",
    "        L= 6381372*math.pi*2\n",
    "        W=L\n",
    "        H=L/2\n",
    "        mill =2.3\n",
    "        x=lon*math.pi/180\n",
    "        y = lat*math.pi/180\n",
    "        y= 1.25*math.log(math.tan(0.25*math.pi+0.4*y))\n",
    "        x = (W/2)+(W/(2*math.pi))*x\n",
    "        y= (H/2)-(H/(2*mill))*y\n",
    "        xy_coordinate.append((int(round(x)),int(round(y)))) \n",
    "        return xy_coordinate\n",
    "\n",
    "    def xy_to_coor(x,y):\n",
    "        lonlat_coordinate =[] \n",
    "        L =6381372 * math.pi*2 \n",
    "        W=L \n",
    "        H=L/2 \n",
    "        mill =2.3\n",
    "        lat = ((H/2-y)*2*mill)/(1.25*H)\n",
    "        lat=((math.atan(math.exp(lat))-0.25*math.pi)*180)/(0.4*math.pi) \n",
    "        lon =(x-W/2)*360/W\n",
    "        lonlat_coordinate.append((round(lon,15),round(lat,15))) \n",
    "        return lonlat_coordinate\n",
    "\n",
    "    latrad_p=latrad;\n",
    "    lonrad_p=lonrad;\n",
    "    for i in range(len(cleanTB_h)-1): \n",
    "        if np.isnan(lonrad[i]) | np.isnan(latrad[i]) | np.isnan(lonrad[i+1]) | np.isnan(latrad[i+1]):\n",
    "            distance_h=0;\n",
    "        else:\n",
    "            distance_h=altrad[i]*0.8391/1000;\n",
    "            resultxy1=millerToXY (lonrad[i],latrad[i])\n",
    "            xrad1=resultxy1[0][0]\n",
    "            yrad1=resultxy1[0][1]\n",
    "            resultxy2=millerToXY (lonrad[i+1],latrad[i+1])\n",
    "            xrad2=resultxy2[0][0]\n",
    "            yrad2=resultxy2[0][1]\n",
    "            if (xrad2-xrad1)==0: \n",
    "                xrad0=xrad1\n",
    "                if yrad2>yrad1:\n",
    "                    yrad0=yrad1+distance_h\n",
    "                else:\n",
    "                    yrad0=yrad1-distance_h\n",
    "                xy0=xy_to_coor(xrad0,yrad0)\n",
    "                lonrad0=xy0[0][0]\n",
    "                latrad0=xy0[0][1]\n",
    "                lonrad_p[i]=lonrad0\n",
    "                latrad_p[i]=latrad0\n",
    "            else:\n",
    "                line_k=(yrad2-yrad1)/(xrad2-xrad1)\n",
    "                line_b=yrad2-line_k*xrad2\n",
    "                if xrad2>xrad1:\n",
    "                    xrad0=math.sqrt(distance_h*distance_h/(1+line_k*line_k))+xrad1\n",
    "                else:\n",
    "                    xrad0=-math.sqrt(distance_h*distance_h/(1+line_k*line_k))+xrad1\n",
    "                yrad0=line_k*xrad0+line_b    \n",
    "                xy0=xy_to_coor(xrad0,yrad0)\n",
    "                lonrad0=xy0[0][0]\n",
    "                latrad0=xy0[0][1]\n",
    "                lonrad_p[i]=lonrad0\n",
    "                latrad_p[i]=latrad0\n",
    "#     print(\"done\")\n",
    "\n",
    "    df=pd.DataFrame({\n",
    "        \"TB_V\":cleanTB_v,\n",
    "        \"TB_H\":cleanTB_h,\n",
    "        \"raw_TB_V\":raw_cleanTB_v,\n",
    "        \"raw_TB_H\":raw_cleanTB_h,\n",
    "        \"lat\":latrad,\n",
    "        \"lon\":lonrad,\n",
    "        \"latp\":latrad_p,\n",
    "        \"lonp\":lonrad_p,\n",
    "        \"soil_moisture\":position_a,\n",
    "        \"alt\":altrad\n",
    "    })\n",
    "\n",
    "    dfpath=fpath+r'TB_soil_oldt.csv'\n",
    "    df.to_csv(dfpath,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
